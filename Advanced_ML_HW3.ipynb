{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced_ML_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGn796VfKkWm"
      },
      "source": [
        "import re\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61O46XB0K4Z8"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/made/adv_ml/corpora/WarAndPeace.txt\", \"r\") as f:\n",
        "    war_and_peace = f.read()\n",
        "\n",
        "train_text = war_and_peace"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOqk1R6VNrZM"
      },
      "source": [
        "**1. Реализуйте базовый частотный метод по Шерлоку Холмсу:**\n",
        "* **подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoaSuMxSLRdN"
      },
      "source": [
        "def preprocess_text(text):\n",
        "    prep_text = re.sub(\"[^а-я ]\", \" \", text.lower())\n",
        "    return re.sub(' +', ' ', prep_text)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfWUaxu_LSXb"
      },
      "source": [
        "def count_frequencies(text):\n",
        "    freqs = {chr(i): 0 for i in range(ord('а'), ord('я') + 1)}\n",
        "    freqs[' '] = 0\n",
        "    \n",
        "    for sym in text:\n",
        "        freqs[sym] += 1\n",
        "    return freqs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HEshVdANMjV"
      },
      "source": [
        "train_text = preprocess_text(train_text)\n",
        "train_unigram_freqs = count_frequencies(train_text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byYWYFt-QTMi",
        "outputId": "ed839381-9c0f-486b-b02c-fef6a4f37009"
      },
      "source": [
        "train_unigram_freqs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 104468,\n",
              " 'а': 45209,\n",
              " 'б': 9310,\n",
              " 'в': 24824,\n",
              " 'г': 11177,\n",
              " 'д': 16387,\n",
              " 'е': 42519,\n",
              " 'ж': 5460,\n",
              " 'з': 9602,\n",
              " 'и': 35838,\n",
              " 'й': 6210,\n",
              " 'к': 19328,\n",
              " 'л': 27277,\n",
              " 'м': 15940,\n",
              " 'н': 35119,\n",
              " 'о': 61282,\n",
              " 'п': 13847,\n",
              " 'р': 24570,\n",
              " 'с': 28128,\n",
              " 'т': 30619,\n",
              " 'у': 15454,\n",
              " 'ф': 1209,\n",
              " 'х': 4600,\n",
              " 'ц': 2179,\n",
              " 'ч': 7349,\n",
              " 'ш': 5090,\n",
              " 'щ': 1514,\n",
              " 'ъ': 283,\n",
              " 'ы': 10233,\n",
              " 'ь': 10498,\n",
              " 'э': 1629,\n",
              " 'ю': 3495,\n",
              " 'я': 12477}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLLqVERGQFoo"
      },
      "source": [
        "* **возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21EUDJYJPjIL"
      },
      "source": [
        "test_text = \"\"\"Надо больше доверять себе, - сказал он. - Пора бы мне знать, что \n",
        "если какой-нибудь факт идет вразрез с длинной цепью логических заключений, \n",
        "значит, его можно истолковать иначе. В коробке лежало две пилюли - в одной \n",
        "содержался смертельный яд, другая - совершенно безвредная. Как это я не \n",
        "догадался раньше, чем увидел коробку\"\"\"\n",
        "\n",
        "test_text = preprocess_text(test_text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSfknloIUyFg"
      },
      "source": [
        "alphabet = sorted(train_unigram_freqs.keys())\n",
        "rand_alphabet = list(np.random.permutation(alphabet))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v_astT_UzEx"
      },
      "source": [
        "def change_alphabet(alphabet_from, alphabet_to, text):\n",
        "    encoded_text = \"\"\n",
        "    for sym in text:\n",
        "        encoded_text += alphabet_to[alphabet_from.index(sym)]\n",
        "    return encoded_text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW9pWXEyY4uI"
      },
      "source": [
        "test_text_encoded = change_alphabet(alphabet, rand_alphabet, test_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "FDVFfiWvcSvc",
        "outputId": "a8a8f430-6cdc-4d94-ffd2-a910803b0651"
      },
      "source": [
        "test_text_encoded"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'хвряъщяпеалъряюлшчйеътлщлъткв впъяхъняшвъщсъмхлъ хвйеъыйяълтпдъквкяэъхдщуреъгвкйъдрлйъюшв шл ътърпдххяэъолнефъпяидылткдцъ вкпфылхдэъ хвыдйълияъмябхяъдтйяпкяювйеъдхвылъюъкяшящклъплбвпяърюлъндпфпдъюъярхяэътярлшбвптчътмлшйлпехсэъчрършуивчътяюлшалххяъщл юшлрхвчъквкъжйяъчъхлъряиврвптчъшвхеалъылмъуюдрлпъкяшящку'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5Jg-eIZdH9w"
      },
      "source": [
        "* **расшифруйте их таким частотным методом**\n",
        "\n",
        "1. Соберем частоты символов в зашифрованном тексте.\n",
        "2. Отсортируем списки частот символов в корпусе и зашифрованном тексте.\n",
        "3. Заменим символы из отсортированного списка символов зашифрованного текста на символы в соответствующих позициях в отсортированном списке символов корпуса."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu4CNAuPpHhW"
      },
      "source": [
        "def sort_alpabet_by_freq(freqs):\n",
        "    return list(map(lambda x: x[0], sorted(freqs.items(), \n",
        "                                           key=lambda x: x[1], \n",
        "                                           reverse=True)))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RarN-WCTcchY"
      },
      "source": [
        "test_unigram_freqs = count_frequencies(test_text_encoded)\n",
        "\n",
        "sorted_train_alphabet = sort_alpabet_by_freq(train_unigram_freqs)\n",
        "sorted_test_alphabet = sort_alpabet_by_freq(test_unigram_freqs)\n",
        "\n",
        "test_text_decoded = change_alphabet(sorted_test_alphabet, sorted_train_alphabet, test_text_encoded)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0gx8o7MFqRWr",
        "outputId": "fbad7199-1cee-419c-9a7f-7909baad6bb7"
      },
      "source": [
        "test_text_decoded"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'иета панмчо тадовукм ропо рлеяен аи жаве пх зио яиекм гка орнс лелаь испбтм юелк сток двеявоя р тнсииаь эожмш наысгорлсщ яелншгоись яиегск оыа зайиа срканладекм сиего д лавапло нойена тдо жсншнс д атиаь ратовйенру рзовконмихь ут твбыеу радовчоииа поядвотиеу лел цка у ио таыетенру веимчо гоз бдстон лаваплб'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eMWvnzosL8q"
      },
      "source": [
        "def calc_accuracy(true_text, pred_text):\n",
        "    coincide = 0\n",
        "    for i in range(len(true_text)):\n",
        "        if true_text[i] == pred_text[i]:\n",
        "            coincide += 1\n",
        "    return coincide / len(true_text) * 100"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Qk6JxKvKGY",
        "outputId": "2f98319d-e922-4135-8ff7-379c96c1c14a"
      },
      "source": [
        "print(f\"Доля правильно расшифрованных букв: {round(calc_accuracy(test_text, test_text_decoded), 2)}%\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля правильно расшифрованных букв: 15.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeVBNc4KwBIJ"
      },
      "source": [
        "**2. Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZ9j_d-wWWD"
      },
      "source": [
        "* **подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uptdXEZHvOf0"
      },
      "source": [
        "def count_bigram_frequencies(text):\n",
        "    freqs = {}\n",
        "\n",
        "    all_combinations = [chr(i) for i in range(ord('а'), ord('я') + 1)]\n",
        "    all_combinations += [' ']\n",
        "\n",
        "    for sym1 in all_combinations:\n",
        "        for sym2 in all_combinations:\n",
        "            freqs[sym1 + sym2] = 0\n",
        "    \n",
        "    for i in range(len(text) - 1):\n",
        "        freqs[text[i] + text[i+1]] += 1\n",
        "    return freqs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifpGEnzDylQV"
      },
      "source": [
        "train_bigram_freqs = count_bigram_frequencies(train_text)\n",
        "test_bigram_freqs = count_bigram_frequencies(test_text_encoded)\n",
        "\n",
        "sorted_train_bigrams_alphabet = sort_alpabet_by_freq(train_bigram_freqs)\n",
        "sorted_test_bigrams_alphabet = sort_alpabet_by_freq(test_bigram_freqs)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVNCAz-JTVOo"
      },
      "source": [
        "* **проведите тестирование аналогично п.1, но при помощи биграмм**\n",
        "\n",
        "1. Для первой биграммы заменим биграмму из отсортированного списка символов зашифрованного текста на биграмму в соответствующей позиции в отсортированном списке символов корпуса.\n",
        "2. Для последующих биграмм находим стартовую позицию для поиска аналогично п.1. Затем, начиная с этой позиции, ищем ближайшую биграмму (до и после текущей позиции), которая начинается с символа, на который заканчивается текущая строка."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TCUeO3zZkJ"
      },
      "source": [
        "def decode_bigrams(alphabet_from, alphabet_to, text):\n",
        "    decoded_text = \"\"\n",
        "    bigram = text[:2]\n",
        "    decoded_text += alphabet_to[alphabet_from.index(bigram)]\n",
        "\n",
        "    for i in range(1, len(text) - 1):\n",
        "        bigram = text[i] + text[i+1]\n",
        "        next = prev = alphabet_from.index(bigram)\n",
        "        \n",
        "        decoded_next = alphabet_to[next]\n",
        "        decoded_prev = alphabet_to[prev]\n",
        "        while decoded_prev[0] != decoded_text[-1] and decoded_next[0] != decoded_text[-1]:\n",
        "            if prev != 0:\n",
        "                prev -= 1\n",
        "            if next != len(alphabet_to) - 1:\n",
        "                next += 1\n",
        "            decoded_next = alphabet_to[next]\n",
        "            decoded_prev = alphabet_to[prev]\n",
        "        if decoded_prev[0] == decoded_text[-1]:\n",
        "            decoded_text += decoded_prev[1]\n",
        "        elif decoded_next[0] == decoded_text[-1]:\n",
        "            decoded_text += decoded_next[1]\n",
        "\n",
        "    return decoded_text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "spOkOSsyS0PB",
        "outputId": "e663e5f5-bbd6-4cb6-8812-4f3976d22b4b"
      },
      "source": [
        "bigrams_decoded_text = decode_bigrams(sorted_test_bigrams_alphabet, sorted_train_bigrams_alphabet, test_text_encoded)\n",
        "bigrams_decoded_text"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'е де бем м стол кры о эт сталазан язая бы жеманале де ры ск этал нал ритуди же ал деговерожеля этран ил жегльк мой илобыл у ану м у бы дня рудемадал был зналя и бы де бы олой а руде м ператру эталеморал ск был нил сль желой этей пей м стал кран и бы я чел де и адоводем стодеру м си уде скобокну бы и ть чт'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-trqog7Cj8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "514abcf1-c3a4-4219-c070-5e4ea7e7f7c6"
      },
      "source": [
        "print(f\"Доля правильно расшифрованных букв: {round(calc_accuracy(test_text, bigrams_decoded_text), 2)}%\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля правильно расшифрованных букв: 13.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYvFS-JZTY28"
      },
      "source": [
        "**3. Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:**\n",
        "\n",
        "* **предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XKzrT_xfFox"
      },
      "source": [
        "1. Начнем с рандомной перестановки символов\n",
        "2. На каждой итерации:\n",
        "* Кандидат в новое состояние - перестановка с обменом местами двух случайно выбранных символов;\n",
        "* $p(x')$ - произведение вероятностей биграмм (вероятности посчитаны на основе корпуса как количество биграмм, деленное на общее число биграмм) в тексте, расшифрованном с помощью новой перестановки;\n",
        "* $p(x_t)$ - произведение вероятностей в тексте, расшифрованном с помощью текущей перестановки;\n",
        "* Вероятность принятия новой перестановки: $P = \\frac{p(x')}{p(x_t)} = e^{log(p(x')-log(p(x_t))}$\n",
        "\n",
        "Процесс запускается несколько раз для определения состояния с наибольшим логарифмом праводоподобия ($log(P))$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSU9r7GcZSy2"
      },
      "source": [
        "* **реализуйте и протестируйте его, убедитесь, что результаты улучшились**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChBQccACnT0D"
      },
      "source": [
        "def calc_log_likelihood(decoded_text, train_freqs):\n",
        "    total_bigrams = np.array(list(train_freqs.values())).sum()\n",
        "    log_likelihood = 0\n",
        "    for i in range(len(decoded_text) - 1):\n",
        "        bigram = decoded_text[i] + decoded_text[i+1]\n",
        "        log_likelihood += np.log(train_freqs[bigram] / total_bigrams + 1e-4)\n",
        "    return log_likelihood"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bglq-UckdxDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d9f98d-ddb3-4193-eec7-ade5863320e6"
      },
      "source": [
        "final_decoded = None\n",
        "max_likelihood = None\n",
        "\n",
        "for j in range(5):\n",
        "    cur_alphabet = alphabet.copy()\n",
        "\n",
        "    for i in range(50000):\n",
        "        test_text_decoded = change_alphabet(cur_alphabet, alphabet, test_text_encoded)\n",
        "\n",
        "        if i % 10000 == 0:\n",
        "            print(f'Текст после итерации {i}: {test_text_decoded}')\n",
        "\n",
        "        cur_likelihood = calc_log_likelihood(test_text_decoded, train_bigram_freqs)\n",
        "\n",
        "        next_alphabet = cur_alphabet.copy()\n",
        "        sym1_idx = np.random.randint(len(next_alphabet))\n",
        "        sym2_idx = np.random.randint(len(next_alphabet)) \n",
        "        while sym2_idx == sym1_idx:\n",
        "            sym2_idx = np.random.randint(len(next_alphabet))\n",
        "        next_alphabet[sym1_idx], next_alphabet[sym2_idx] = next_alphabet[sym2_idx], next_alphabet[sym1_idx]\n",
        "\n",
        "        test_text_decoded = change_alphabet(next_alphabet, alphabet, test_text_encoded)\n",
        "        next_likelihood = calc_log_likelihood(test_text_decoded, train_bigram_freqs)\n",
        "\n",
        "        accept = False\n",
        "        if next_likelihood > cur_likelihood:\n",
        "            accept = True\n",
        "        else:\n",
        "            accept = np.random.rand() < (np.exp(next_likelihood - cur_likelihood))\n",
        "\n",
        "        if accept:\n",
        "            cur_alphabet = next_alphabet\n",
        "    \n",
        "    test_text_decoded = change_alphabet(cur_alphabet, alphabet, test_text_encoded)\n",
        "    fin_likelihood = calc_log_likelihood(test_text_decoded, train_bigram_freqs) \n",
        "    if max_likelihood is None:\n",
        "        max_likelihood = fin_likelihood\n",
        "        final_decoded = test_text_decoded\n",
        "    elif fin_likelihood >= max_likelihood:\n",
        "        max_likelihood = fin_likelihood\n",
        "        final_decoded = test_text_decoded\n",
        "    print(f\"Log likelihood {j}: {fin_likelihood}\", end='\\n\\n')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Текст после итерации 0: хвряъщяпеалъряюлшчйеътлщлъткв впъяхъняшвъщсъмхлъ хвйеъыйяълтпдъквкяэъхдщуреъгвкйъдрлйъюшв шл ътърпдххяэъолнефъпяидылткдцъ вкпфылхдэъ хвыдйълияъмябхяъдтйяпкяювйеъдхвылъюъкяшящклъплбвпяърюлъндпфпдъюъярхяэътярлшбвптчътмлшйлпехсэъчрършуивчътяюлшалххяъщл юшлрхвчъквкъжйяъчъхлъряиврвптчъшвхеалъылмъуюдрлпъкяшящку\n",
            "Текст после итерации 10000: наве делыхо вегоряты содо сказал ен бера дь пно знаты мте осли какей нидувы факт ивот гразроз с влинней чобыю лешимоскиц заклюмоний знамит оше пежне истелкегаты инамо г кередко ложале вго билюли г евней севоржался спортолыньй яв врушая сегорхонне дозгровная как эте я но вешавался раныхо моп угивол кередку\n",
            "Текст после итерации 20000: наде бельхо дегорять собо свазал ен пера бы мно знать кте осли вавей нибудь чавт идот гразроз с длинней щопью лежикосвиц завлюконий знакит оже мешне истелвегать инако г веребво лошале дго пилюли г едней седоршался смортольный яд дружая сегорхонне бозгродная вав эте я но дежадался раньхо ком угидол веребву\n",
            "Текст после итерации 30000: наво больше водерять себе сказал он пора бы мне знать что если какой нибувь жакт ивет дразрез с влинной фепью логическиц заключений значит его мохно истолкодать иначе д коробке лехало вде пилюли д овной соверхался смертельный яв вругая содершенно бездревная как это я не вогавался раньше чем удивел коробку\n",
            "Текст после итерации 40000: надо больше доверять себе сказал он пора бы мне знать что если какой нибудь цакт идет вразрез с длинной щепью логических заключений значит его можно истолковать иначе в коробке лежало две пилюли в одной содержался смертельный яд другая совершенно безвредная как это я не догадался раньше чем увидел коробку\n",
            "Log likelihood 0: -1690.3430830596442\n",
            "\n",
            "Текст после итерации 0: хвряъщяпеалъряюлшчйеътлщлъткв впъяхъняшвъщсъмхлъ хвйеъыйяълтпдъквкяэъхдщуреъгвкйъдрлйъюшв шл ътърпдххяэъолнефъпяидылткдцъ вкпфылхдэъ хвыдйълияъмябхяъдтйяпкяювйеъдхвылъюъкяшящклъплбвпяърюлъндпфпдъюъярхяэътярлшбвптчътмлшйлпехсэъчрършуивчътяюлшалххяъщл юшлрхвчъквкъжйяъчъхлъряиврвптчъшвхеалъылмъуюдрлпъкяшящку\n",
            "Текст после итерации 10000: надо больше доверять себе сказал он пора бы мне знать что если какой нибудь хакт идет вразрез с длинной щепью логическиц заключений значит его можно истолковать иначе в коробке лежало две пилюли в одной содержался смертельный яд другая совершенно безвредная как это я не догадался раньше чем увидел коробку\n",
            "Текст после итерации 20000: надо больше доверять себе сказал он пора бы мне знать что если какой нибудь щакт идет вразрез с длинной ъепью логических заключений значит его можно истолковать иначе в коробке лежало две пилюли в одной содержался смертельный яд другая совершенно безвредная как это я не догадался раньше чем увидел коробку\n",
            "Текст после итерации 30000: надо больже доверять себе сказал он пора бы мне знать что если какой нибудь щакт идет вразрез с длинной цепью лошических заключений значит ешо могно истолковать иначе в коробке легало две пилюли в одной содергался смертельный яд друшая соверженно безвредная как это я не дошадался раньже чем увидел коробку\n",
            "Текст после итерации 40000: наво больше водерять себе сказал он пора бы мне знать что если какой нибувь хакт ивет дразрез с влинной щепью логическиф заключений значит его можно истолкодать иначе д коробке лежало вде пилюли д овной совержался смертельный яв вругая содершенно бездревная как это я не вогавался раньше чем удивел коробку\n",
            "Log likelihood 1: -1689.6449560383655\n",
            "\n",
            "Текст после итерации 0: хвряъщяпеалъряюлшчйеътлщлъткв впъяхъняшвъщсъмхлъ хвйеъыйяълтпдъквкяэъхдщуреъгвкйъдрлйъюшв шл ътърпдххяэъолнефъпяидылткдцъ вкпфылхдэъ хвыдйълияъмябхяъдтйяпкяювйеъдхвылъюъкяшящклъплбвпяърюлъндпфпдъюъярхяэътярлшбвптчътмлшйлпехсэъчрършуивчътяюлшалххяъщл юшлрхвчъквкъжйяъчъхлъряиврвптчъшвхеалъылмъуюдрлпъкяшящку\n",
            "Текст после итерации 10000: наве гелыхо вепоряты сого сдазал ен бера гц мно знаты кте осли дадей нигувы фадт ивот празроз с влинней чобыь лежикосдию задльконий знакит оже мешне истелдепаты инако п дерегдо лошале впо бильли п евней севоршался смортолынцй яв вружая сепорхонне гозпровная дад эте я но вежавался раныхо ком упивол дерегду\n",
            "Текст после итерации 20000: надо больше доверять себе сказал он пора бы мне знать что если какой нибудь хакт идет вразрез с длинной ъепью логическиц заключений значит его можно истолковать иначе в коробке лежало две пилюли в одной содержался смертельный яд другая совершенно безвредная как это я не догадался раньше чем увидел коробку\n",
            "Текст после итерации 30000: надо больше доверять себе сказал он пора бы мне знать что если какой нибудь факт идет вразрез с длинной цепью логических заключений значит его можно истолковать иначе в коробке лежало две пилюли в одной содержался смертельный яд другая совершенно безвредная как это я не догадался раньше чем увидел коробку\n",
            "Текст после итерации 40000: наво больше водерять себе сказал он пора бы мне знать что если какой нибувь цакт ивет дразрез с влинной щепью логических заключений значит его можно истолкодать иначе д коробке лежало вде пилюли д овной совержался смертельный яв вругая содершенно бездревная как это я не вогавался раньше чем удивел коробку\n",
            "Log likelihood 2: -1690.7031685614254\n",
            "\n",
            "Текст после итерации 0: хвряъщяпеалъряюлшчйеътлщлъткв впъяхъняшвъщсъмхлъ хвйеъыйяълтпдъквкяэъхдщуреъгвкйъдрлйъюшв шл ътърпдххяэъолнефъпяидылткдцъ вкпфылхдэъ хвыдйълияъмябхяъдтйяпкяювйеъдхвылъюъкяшящклъплбвпяърюлъндпфпдъюъярхяэътярлшбвптчътмлшйлпехсэъчрършуивчътяюлшалххяъщл юшлрхвчъквкъжйяъчъхлъряиврвптчъшвхеалъылмъуюдрлпъкяшящку\n",
            "Текст после итерации 10000: елт об ирзнот внагкромнбномялдлио еой алобщоженоделкроьк онмисояля поесбчтрофлякостнковалдандомотисее поънйрцои усьнмясходляицьнесподельскону ож ые осмк ия влкросельновоя а бяноиныли отвнойсицисово те пом тнаылимгомжнакнирещпогтотачулгом вназнее обндвантелгояляошк огоенот ултлимгоалерзноьнжочвстниоя а бяч\n",
            "Текст после итерации 20000: елт об иржнот внагкромнбномялдлио еой алобцоченоделкроьк онмисояля поесбзтроэлякостнковалдандомотисее поюнйршои усьнмясфодляишьнесподельскону оч ые осмк ия влкросельновоя а бяноиныли отвнойсишисово те пом тнаылимгомчнакнирецпогтотазулгом внажнее обндвантелгояляохк огоенот ултлимгоалержноьнчозвстниоя а бяз\n",
            "Текст после итерации 30000: елт оз иржнот внагкромнзномялдлио еой алозхобеноделкроьк онмисояля поесзчтрошлякостнковалдандомотисее поънйрцои усьнмясэодляицьнесподельскону об ые осмк ия влкросельновоя а зяноиныли отвнойсицисово те пом тнаылимгомбнакнирехпогтотачулгом внажнее озндвантелгояляоюк огоенот ултлимгоалержноьнбочвстниоя а зяч\n",
            "Текст после итерации 40000: елт оз иржнот внагкромнзномялдлио еой алозхоыеноделкроьк онмисояля поесзчтрофлякостнковалдандомотисее поэнйрцои усьнмясъодляицьнесподельскону оы бе осмк ия влкросельновоя а зяноинбли отвнойсицисово те пом тнаблимгомынакнирехпогтотачулгом внажнее озндвантелгояляошк огоенот ултлимгоалержноьныочвстниоя а зяч\n",
            "Log likelihood 3: -1866.9351447236781\n",
            "\n",
            "Текст после итерации 0: хвряъщяпеалъряюлшчйеътлщлъткв впъяхъняшвъщсъмхлъ хвйеъыйяълтпдъквкяэъхдщуреъгвкйъдрлйъюшв шл ътърпдххяэъолнефъпяидылткдцъ вкпфылхдэъ хвыдйълияъмябхяъдтйяпкяювйеъдхвылъюъкяшящклъплбвпяърюлъндпфпдъюъярхяэътярлшбвптчътмлшйлпехсэъчрършуивчътяюлшалххяъщл юшлрхвчъквкъжйяъчъхлъряиврвптчъшвхеалъылмъуюдрлпъкяшящку\n",
            "Текст после итерации 10000: енил уломэт илктаяым втут всндно ле план уй зет деным чыл твор снсль ерушим фнсы риты кандатд в иореель ютпмг олбрчтвсрх днсогчтерь денчры тбл злжел рвылослкным ренчт к слалуст отжнол икт прогор к лиель влитажновя взтаытомейь яи иашбня влктаэтеел утдкатиеня снс цыл я ет илбниновя анемэт чтз шкрито слалусш\n",
            "Текст после итерации 20000: енил уломэт илктаяым втут всндно ле блан ую пет деным чыл твор снсль ерузим фнсы риты кандатд в иореель штбмй олгрчтвсрх днсойчтерь денчры тгл плжел рвылослкным ренчт к слалуст отжнол икт бройор к лиель влитажновя вптаытомеюь яи иазгня влктаэтеел утдкатиеня снс цыл я ет илгниновя анемэт чтп зкрито слалусз\n",
            "Текст после итерации 30000: енил улойчт илктаяый стут сднвно ле цлан уз пет веный эыл тсор дндль еруший щнды риты канватв с иореель хтцйм олгрэтсдрю вндомэтерь венэры тгл плжел рсылодлкный ренэт к длалудт отжнол икт цромор к лиель слитажнося сптаытойезь яи иашгня слктачтеел утвкатиеня днд был я ет илгнинося анейчт этп шкрито длалудш\n",
            "Текст после итерации 40000: енил улойэт илктаяый стут сднвно ле флан ую пет веный чыл тсор дндль ерузий хнды риты канватв с иореель штфйм олгрчтсдръ вндомчтерь венчры тгл плжел рсылодлкный ренчт к длалудт отжнол икт фромор к лиель слитажнося сптаытойеюь яи иазгня слктаэтеел утвкатиеня днд был я ет илгнинося анейэт чтп зкрито длалудз\n",
            "Log likelihood 4: -1828.3812975259675\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pA8DfoZ4m1ft",
        "outputId": "f5429524-dba8-4ed7-d79e-eeb211c13852"
      },
      "source": [
        "final_decoded"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'наво больше водерять себе сказал он пора бы мне знать что если какой нибувь факт ивет дразрез с влинной цепью логических заключений значит его можно истолкодать иначе д коробке лежало вде пилюли д овной совержался смертельный яв вругая содершенно бездревная как это я не вогавался раньше чем удивел коробку'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMpMoznQfoR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd2e239b-291b-4761-cbbf-ed62476257ac"
      },
      "source": [
        "print(f\"Доля правильно расшифрованных букв: {round(calc_accuracy(test_text, final_decoded), 2)}%\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Доля правильно расшифрованных букв: 92.48%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlc6yWOCwT_s"
      },
      "source": [
        "**4. Расшифруйте сообщение:**\n",
        "**←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq6qTY7LrMtR"
      },
      "source": [
        "Аналогично п.3, но добавлены 5 символов к алфавиту зашифрованного сообщения, чтобы выравнять количество символов в алфавитах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLmmSfeigF4M"
      },
      "source": [
        "encoded_message = \"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zR2lDp-x77g",
        "outputId": "f8e41200-820c-4508-e12d-d1379d5756c2"
      },
      "source": [
        "final_decoded = None\n",
        "max_likelihood = None\n",
        "\n",
        "for j in range(5):\n",
        "    cur_alphabet = list(set(encoded_message)) + ['!', '@', '#', '$', '%']\n",
        "\n",
        "    for i in range(50000):\n",
        "        test_text_decoded = change_alphabet(cur_alphabet, alphabet, encoded_message)\n",
        "\n",
        "        if i % 10000 == 0:\n",
        "            print(f'Текст после итерации {i}: {test_text_decoded}')\n",
        "\n",
        "        cur_likelihood = calc_log_likelihood(test_text_decoded, train_bigram_freqs)\n",
        "\n",
        "        next_alphabet = cur_alphabet.copy()\n",
        "        sym1_idx = np.random.randint(len(next_alphabet))\n",
        "        sym2_idx = np.random.randint(len(next_alphabet)) \n",
        "        while sym2_idx == sym1_idx:\n",
        "            sym2_idx = np.random.randint(len(next_alphabet))\n",
        "        next_alphabet[sym1_idx], next_alphabet[sym2_idx] = next_alphabet[sym2_idx], next_alphabet[sym1_idx]\n",
        "\n",
        "        test_text_decoded = change_alphabet(next_alphabet, alphabet, encoded_message)\n",
        "        next_likelihood = calc_log_likelihood(test_text_decoded, train_bigram_freqs)\n",
        "\n",
        "        accept = False\n",
        "        if next_likelihood > cur_likelihood:\n",
        "            accept = True\n",
        "        else:\n",
        "            accept = np.random.rand() < (np.exp(next_likelihood - cur_likelihood))\n",
        "\n",
        "        if accept:\n",
        "            cur_alphabet = next_alphabet\n",
        "    \n",
        "    test_text_decoded = change_alphabet(cur_alphabet, alphabet, encoded_message)\n",
        "    fin_likelihood = calc_log_likelihood(test_text_decoded, train_bigram_freqs) \n",
        "    if max_likelihood is None:\n",
        "        max_likelihood = fin_likelihood\n",
        "        final_decoded = test_text_decoded\n",
        "    elif fin_likelihood >= max_likelihood:\n",
        "        max_likelihood = fin_likelihood\n",
        "        final_decoded = test_text_decoded\n",
        "    print(f\"Log likelihood {j}: {fin_likelihood}\", end='\\n\\n')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Текст после итерации 0: схпкбйгбйкикцсбмчъовптмглбкпкбрчдцкбмчъовптмглбцснхцбшбецч чбхччжфсмкзбнчцчъглбпс нчбръчдкцвцтбхнчъссбйхс чбйгбйхсбхиспвпкбръвйкптмчбкбрчпшдкцсбовнхковптмглбжвппбщвбрчхпсимссбдсцйсъцчсбщвивмксбншъхвбачцзбнчмсдмчбзбмкдс чбмсбчжсфву\n",
            "Текст после итерации 10000: если вы вимите норзальный или подти норзальный текст у этого соочшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный чалл ба послемнее детвертое бамание курса хотя конедно я нидего не очешащ\n",
            "Текст после итерации 20000: если вы вимите норзальный или почти норзальный текст у этого соодцения который легко прочитать скорее всего вы все смелали правильно и получите заксизальный далл жа послемнее четвертое жамание курса ботя конечно я ничего не одецаш\n",
            "Текст после итерации 30000: если вы визите нордальный или помти нордальный текст у чтого сообжения который легко промитать скорее всего вы все сзелали правильно и полумите даксидальный балл фа послезнее метвертое фазание курса хотя конемно я нимего не обежаю\n",
            "Текст после итерации 40000: если вы вимите норзальный или подти норзальный текст у этого сообшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обешаж\n",
            "Log likelihood 0: -1238.570650865833\n",
            "\n",
            "Текст после итерации 0: схпкбйгбйкикцсбмчъовптмглбкпкбрчдцкбмчъовптмглбцснхцбшбецч чбхччжфсмкзбнчцчъглбпс нчбръчдкцвцтбхнчъссбйхс чбйгбйхсбхиспвпкбръвйкптмчбкбрчпшдкцсбовнхковптмглбжвппбщвбрчхпсимссбдсцйсъцчсбщвивмксбншъхвбачцзбнчмсдмчбзбмкдс чбмсбчжсфву\n",
            "Текст после итерации 10000: нвитоскостытено райлим кпотитобрьето райлим кпоендвеозожеруроврршхн тгодреракпоинудробарьтелемовдранносвнуроскосвновынилитобалстим ротобризьтенойлдвтйлим кпошлииоюлобрвины нноьнеснаерноюлыл тнодзавлоэрегодр нь рого тьнуро норшнхлч\n",
            "Текст после итерации 20000: нтивоскосвьвено рашлим кховивопрыево рашлим кхоендтеозочеруротрржцн вгодреракхоинудропарывелемотдранностнуроскостнотьниливопалсвим ровопризывеношлдтвшлим кхожлииоялопртинь нноынеснаернояльл внодзатлобрегодр ны рого вынуро норжнцлй\n",
            "Текст после итерации 30000: нтивоспосвьвено рашлим пговивокрыево рашлим пгоендтеозожеруротррбян входрерапгоинудрокарывелемотдранностнуроспостнотьниливокалсвим ровокризывеношлдтвшлим пгоблииойлокртинь нноынеснаернойльл внодзатлофреходр ны рохо вынуро норбнялю\n",
            "Текст после итерации 40000: нвитоспостытено раглим пкотитобряето раглим пкоендвеозочеруроврржщн тходрерапкоинудробарятелемовдранносвнуроспосвновынилитобалстим ротобризятеноглдвтглим пкожлииойлобрвины нноянеснаернойлыл тнодзавлофреходр ня рохо тянуро норжнщлъ\n",
            "Log likelihood 1: -1373.2485728532426\n",
            "\n",
            "Текст после итерации 0: схпкбйгбйкикцсбмчъовптмглбкпкбрчдцкбмчъовптмглбцснхцбшбецч чбхччжфсмкзбнчцчъглбпс нчбръчдкцвцтбхнчъссбйхс чбйгбйхсбхиспвпкбръвйкптмчбкбрчпшдкцсбовнхковптмглбжвппбщвбрчхпсимссбдсцйсъцчсбщвивмксбншъхвбачцзбнчмсдмчбзбмкдс чбмсбчжсфву\n",
            "Текст после итерации 10000: свентылтынянасто куреголчтненть данто куреголчтасиватйтша м тв  бъсонэти а клчтесми тьк днарагтви ксстывсм тылтывствясерентькрынего тнть ейднастуривнуреголчтбреетпрть весяосстдсаыска стпряронстийквртф аэти осдо тэтондсм тост бсърх\n",
            "Текст после итерации 20000: свертыйтырдрасто кунегойэтрерть парто кунегойэтасиватлтца м тв  зясорчти а кйэтесми тьк пранагтви ксстывсм тыйтывствдсенертькнырего трть елпрастуниврунегойэтзнеетжнть весдосстпсаыска стжнднорстилквнтю ачти оспо тчторпсм тост зсянщ\n",
            "Текст после итерации 30000: свертултурдрасто кзнеголятрерть парто кзнеголятасиватхтща м тв  бысорчти а клятесми тьк пранагтви ксстувсм тултувствдсенертькнурего трть ехпрастзниврзнеголятбнеетшнть весдосстпсауска стшнднорстихквнтй ачти оспо тчторпсм тост бсынъ\n",
            "Текст после итерации 40000: свертубтурдрасто кжнегобытрерть парто кжнегобытасиватхтца л тв  змсоряти а кбытесли тьк пранагтви ксстувсл тубтувствдсенертькнурего трть ехпрастжнивржнегобытзнеетчнть весдосстпсауска стчнднорстихквнтй аяти оспо тяторпсл тост зсмнэ\n",
            "Log likelihood 2: -1377.4978365222391\n",
            "\n",
            "Текст после итерации 0: схпкбйгбйкикцсбмчъовптмглбкпкбрчдцкбмчъовптмглбцснхцбшбецч чбхччжфсмкзбнчцчъглбпс нчбръчдкцвцтбхнчъссбйхс чбйгбйхсбхиспвпкбръвйкптмчбкбрчпшдкцсбовнхковптмглбжвппбщвбрчхпсимссбдсцйсъцчсбщвивмксбншъхвбачцзбнчмсдмчбзбмкдс чбмсбчжсфву\n",
            "Текст после итерации 10000: нтав см свывин оершлакому вав педив оершлакому инчти г эиеце теезьновя чеиерму анцче предвилик тчернн стнце см стн тыналав прлсвакое в пеагдвин шлчтвшлакому злаа бл петаныонн дниснриен блыловн чгртл жеия чеондое я овднце он езньлю\n",
            "Текст после итерации 20000: отав ся свывио нерулакняь вав педив нерулакняь иочти з хиеже теегйонвм чеиеряь аожче предвилик тчероо стоже ся сто тыоалав прлсвакне в пеаздвио улчтвулакняь глаа бл петаоыноо доисориео блылнво чзртл шеим ченодне м нвдоже но егойлц\n",
            "Текст после итерации 30000: етан чы чньние ворулазвый нан подин ворулазвый иести к эиомо тоогцевня соиорый аемсо проднилиз тсорее чтемо чы чте тьеалан прлчназво н поакдние улстнулазвый глаа бл потаеьвее деичериое бльлвне скртл хоия соведво я вндемо ве огецлщ\n",
            "Текст после итерации 40000: етан сы сньние ворулазвый нан подин ворулазвый иекти г чиомо тообцевня коиорый аемко проднилиз ткорее стемо сы сте тьеалан прлсназво н поагдние улктнулазвый блаа хл потаеьвее деисериое хльлвне кгртл фоия коведво я вндемо ве обецлю\n",
            "Log likelihood 3: -1318.1675908059685\n",
            "\n",
            "Текст после итерации 0: схпкбйгбйкикцсбмчъовптмглбкпкбрчдцкбмчъовптмглбцснхцбшбецч чбхччжфсмкзбнчцчъглбпс нчбръчдкцвцтбхнчъссбйхс чбйгбйхсбхиспвпкбръвйкптмчбкбрчпшдкцсбовнхковптмглбжвппбщвбрчхпсимссбдсцйсъцчсбщвивмксбншъхвбачцзбнчмсдмчбзбмкдс чбмсбчжсфву\n",
            "Текст после итерации 10000: если вы вимите норзальный или подти норзальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса шотя конедно я нидего не обещаж\n",
            "Текст после итерации 20000: если вы вимите норзальный или подти норзальный текст у чтого соожшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный жалл ба послемнее детвертое бамание курса хотя конедно я нидего не ожешащ\n",
            "Текст после итерации 30000: если вы вимите норзальный или подти норзальный текст у этого сообщения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса хотя конедно я нидего не обещаъ\n",
            "Текст после итерации 40000: если вы вимите норзальный или подти норзальный текст у этого соочжения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный чалл ба послемнее детвертое бамание курса шотя конедно я нидего не очежах\n",
            "Log likelihood 4: -1245.6416923312167\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOqvu0bvyb6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a879e15d-5706-4d38-e832-a628433c7f48"
      },
      "source": [
        "final_decoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'если вы вимите норзальный или подти норзальный текст у этого сообшения который легко продитать скорее всего вы все смелали правильно и полудите заксизальный балл ча послемнее детвертое чамание курса цотя конедно я нидего не обешаю'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xVHsakGsM3l"
      },
      "source": [
        "если вы видите нормальный или почти нормальный текст у этого сообщения который легко прочитать скорее всего вы все сделали правильно и получите максимальный балл за последнее четвертое задание курса хотя конечно я ничего не обещаю"
      ]
    }
  ]
}